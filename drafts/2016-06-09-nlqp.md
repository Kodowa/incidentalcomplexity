### Natural Language Querying

As if Eve wasn't enough work already, we decided to add a natural language (NL) interface. While we recognized at the outset that natural language processing (NLP) is one of the hardest problems all of science and engineering, we couldn't resist its siren song. I mean, what could be better for non-programmers than the ability to write a program in plain English (or their native language of choice)? Think what that would mean for the accessibility of a language. 

But we thought we had a sufficiently constrained version of the problem that perhaps we had a shot at it. Let me explain...

Typical NLP tasks include machine translation, article summarization, sentiment analysis, part-of-speech tagging, coreference resolution, and named entity recognition. Today's best approaches train a classifier using a large corpus of annotated training text. Depending on the text and task, performance ranges from impressive (POS tagging, coreference resolution) to spotty (article summarization, sentiment analysis).

Our NLP task was very specific: to turn a plain english query into a formal query recognized by the Eve. Thus, we leveraged a number of assumption that simplified the problem to what we hoped was something tractable.   

1. We only had to deal with a single class of text: questions, no longer than a sentence, so we didn't have to deal with trying to understand a whole news article, for example.
2. Users could only ask about entities in the Eve database, so entity recognition was just a lookup.
3. People typically ask questions in a limited number of ways, which are typically concise. We didn't worry about flowery language or complex sentence structure.
4. Again, since you can only ask questions about data in the database, any ambiguities could be enumerated and presented to the user. 

Thus, we hoped we could just rely on a set of heuristics, which we could write to cover the general cases and then refine over time to get the edge cases. For instance, the query `"What is Corey's age?"` would be transformed into the s-exp we showed in the last section: 

```
(query
	(select "eavs" :entity "corey" :attribute "age" :value corey|age)
	(project! "corey's age" :age corey|age))
```

### Method

How does this work? As mentioned before, we used a rule-based approach rather than a statistical machine learning approach. While learning approaches have proven to be very effective, they require a large amount of tagged and classified training data, which can be expensive to obtain. For our problem, this data would be a mapping from a plain english query to a formal query. We just didn't have this. But rules-based approaches have their own advantages:

1.  A rules-based approach is light-weight and can easily be stored on the client. We don't need training data, which also means we don't have to host a model on a server or ship it to the client.
2.  A rules-based approach an be improved simply by adding a new rule. Statistical approaches require re-training to improve performance, which can take an inordinately long time. Then because of (1), we have to re-ship the new model to the client somehow..
3. The rules-based approach is easy to reason about, since the rules are generated and encoded by humans. Statistical models use thousands to millions of automatically generated weights to arrive at decisions. It's very hard to reason about how or why the classifer behaved the way it did beyond "Well, it made that decision because the weights told it to."
4. Rules-based approaches are blazingly fast. Our parser did its job in ~1ms in Chrome. The best performance we could get out of a comparable statistical parser was 20ms, and that wasn't even in the browser.

So anyway, back to the original question: how did it work? Well if you *really* want to know, then take a look at the source [here](https://github.com/witheve/Eve/blob/c7878849e8a7c5991e4b78914e1220bc1330969a/src/NLQueryParser.ts). I'll go through the process step-by-step with the example query `"What is the average salary per department?"`

#### Tokens

The high-level overview is first we break the string at whitespace boundaries. To facilitate matching, we normalize the words by depluralizing and lowercasing them. Then we tag each word with a part of speach, which is just referenced in a small dictionary. Any word not in the dictionary is tagged a noun. Our example query tokenizes like this:

```
------------------------------------
   WORD        | NORM WORD  | POS  |
------------------------------------
0: root        | root       | NOUN | 
1: What        | what       | GLUE | 
2: is          | is         | VERB | 
3: the         | the        | GLUE | 
4: average     | average    | NOUN | 
5: salary      | salary     | NOUN | 
6: per         | per        | GLUE | 
7: department? | department | NOUN | 
``` 

#### Nodes

Next, we classify each token in the context of the Eve database. First we [n-gram](https://en.wikipedia.org/wiki/N-gram) the words and match each one against the database. This determines the class of a word, whether it's an entity, attribute, value, collection, or function. In our example, `average` and `per` are functions, `salary` is an attribute, and `department` is a collection.  

```
--------------------------------------------------------
   WORD        | NORM WORD  | POS  | PROPERTIES
--------------------------------------------------------
0: root        | root       | NOUN | (IMPLICIT|ROOT)
1: What        | what       | GLUE | 
2: is          | is         | VERB | 
3: the         | the        | GLUE | 
4: average     | average    | NOUN | (FUNCTION)
5: salary      | salary     | NOUN | (ATTRIBUTE)
6: per         | per        | GLUE | (GROUPING|FUNCTION)
7: department? | department | NOUN | (COLLECTION)
```

#### Tree

Next, we form a tree with the tagged and classified words, which represents the relationships between the words. Most importantly, we care about the relationships between nouns, which at this point were found in the database. If all nouns are not matched, the parse cannot proceed. Relationships between nouns are found through a truncated graph search; we store links between entities and collections in Eve, and then try to find a path between each noun. For example, in if the query were `"Salaries per department"`, we first look up `salary` and `department` in `links` table. We find there is no direct link, so we try to find a 1-degree link, which is found through the `employee` collection (employees have salaries and belong to a department).

```
|*0: root  (IMPLICIT|ROOT)
|* 6: per [group] (GROUPING|FUNCTION)
|*  0: root  (IMPLICIT|ROOT)
|*   4: average [average] (FUNCTION)
|*    0: average  (IMPLICIT|ARGUMENT|OUTPUT|OUTPUT)
|*     0: output0 [output0] (IMPLICIT|OUTPUT)
|*    0: value  (IMPLICIT|ARGUMENT|INPUT|ATTRIBUTE)
|*     5: salary [employee|salary] (ATTRIBUTE)
|*   0: department [department] (IMPLICIT|ATTRIBUTE)
|*  0: collection  (IMPLICIT|ARGUMENT|INPUT|COLLECTION|ATTRIBUTE)
|*   7: department [department] (COLLECTION)
```

Notice the implicit nodes in the tree. These come from functions, which are added to the tree as a subtree. For instance, the `average` function takes two children: an input and an output. The `per` function takes two inputs as well: a body and a collection over which to group the body. By adding these subtrees, we ensure that the query plan is fully specified before we try to turn it into a s-exp.

#### Formal Query

Once we have the fully formed tree, converting it to a s-exp query is straight forward, as the tree structure was designed to directly map to the s-exp grammar. The s-exp for our example is

```
(query
	(select "tags" :entity department :collection "department")
	(query
		(select "eavs" :entity employee :attribute "salary" :value employee|salary)
		(select "eavs" :entity employee :attribute "department" :value department)
		(select "tags" :entity employee :collection "employee")
		(select "tags" :entity department :collection "department")
		(select "average" :average output0 :value employee|salary))
	(project! :average output0 :department department))
```

Which you can see is almost a direct translation of the tree. One major difference is that we inline the children of functions as arguments. Also, the grouping function `per` is implicitly represented by the subquery. 

And that's it. The client sends this s-exp to the Eve sever, and the server returns a result. In this case: 

```
--------------------------------
| AVERAGE SALARY | DEPARTMENT  | 
--------------------------------
| 8.5            | engineering |     
| 10             | operations  |     
--------------------------------
```

### Results

This looked pretty great to us at the time. It appeared we had a system that could generate a relatively complex query from a simple english query. But how does this generalize? Well, again, we didn't have any data on what kind of questions people would ask. The best we could do was try and grow the space of acceptable queries as large as we could, and then release to the public, updating the rules as we find queries that break the system.

So we did exactly that; in February we released [WikiEve]() to the public and the queries started rolling in.... and almost immediately people started breaking all the assumptions we made. Of course we knew things would break once we released WikiEve to the wild. Most of the problems seemed very fixable until two:

First, a sizeable portion of users had trouble formulating what they wanted as a query to begin with. This really surprised us, because these same users have no problem formulating vague questions for Google searches. When it comes to specific searches for their own data, some users expressed that they didn't even know where to begin.

Second, we encountered a query that really gave us pause: `"Which planets are uninhabitable?"`

On the surface, this seems okay. We had a database of planets, and only one of them was tagged `"habitable"`. We expected most people would negate this as `"Which planets are not habitable?"`. But look at the word "uninhabitable"? This word is nefarious. First consider just the prefix "in-", which commonly negates the root word. "Insecure", "inaccurate", "inanimate", "indifferent", "incoherent". But "inhabitable" does not mean "not habitable". It still means "habitable". If I were to write a general heuristic to handle "in-" based on its common meaning, it would classify "inhabitable" as "not habitable". Then "uninhabitable", which contains a double negative prefix (i.e. "un-", "in-"), would be classified as "habitable". Oh my...

### Lessons Learned

So where do we go from here? The first problem one might be okay; we intentionally didn't explain how the system worked in the hope that users would figure it out on their own. But I think it pointed to a deeper issue, namely that the text interface needed to be augmented with another interface to guide the formulation of an english query.

The second issue was pretty much a show stopper though. All the solutions we came up with to solve the problem in a general way involved statistics, machine learning, and training data. This put us back at square one, since we have no training data.

We all agreed that we could spend an arbitrary amount of time developing a system that meets our requirements. But first of all, it looks like a NL interface might not be the UI panacea we thought it was. Second, we're not a NL company; we're building a programming language, and the NL interface was only created to support that Eve. So we decided to abandon the effort (at least for now).